name: Benchmarks

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

env:
  CARGO_TERM_COLOR: always

jobs:
  benchmark:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Cache cargo registry
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: ${{ runner.os }}-cargo-bench-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-bench-

      - name: Run serialization benchmarks
        run: cargo bench --package hazelcast-client --bench serialization_benchmarks -- --noplot

      - name: Run map benchmarks
        run: cargo bench --package hazelcast-client --bench map_benchmarks -- --noplot

      - name: Run queue benchmarks
        run: cargo bench --package hazelcast-client --bench queue_benchmarks -- --noplot

      - name: Store benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: target/criterion/
          retention-days: 30

  benchmark-comparison:
    name: Benchmark Comparison (PR only)
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Cache cargo registry
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: ${{ runner.os }}-cargo-bench-compare-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-bench-compare-

      - name: Install critcmp
        run: cargo install critcmp

      - name: Run benchmarks on PR branch
        run: |
          cargo bench --package hazelcast-client --bench serialization_benchmarks -- --save-baseline pr
          cargo bench --package hazelcast-client --bench map_benchmarks -- --save-baseline pr
          cargo bench --package hazelcast-client --bench queue_benchmarks -- --save-baseline pr

      - name: Checkout base branch
        run: git checkout ${{ github.base_ref }}

      - name: Run benchmarks on base branch
        run: |
          cargo bench --package hazelcast-client --bench serialization_benchmarks -- --save-baseline base
          cargo bench --package hazelcast-client --bench map_benchmarks -- --save-baseline base
          cargo bench --package hazelcast-client --bench queue_benchmarks -- --save-baseline base

      - name: Compare benchmarks
        run: |
          echo "## Serialization Benchmarks" >> $GITHUB_STEP_SUMMARY
          critcmp base pr --filter serialization >> $GITHUB_STEP_SUMMARY || true
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Map Benchmarks" >> $GITHUB_STEP_SUMMARY
          critcmp base pr --filter map >> $GITHUB_STEP_SUMMARY || true
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Queue Benchmarks" >> $GITHUB_STEP_SUMMARY
          critcmp base pr --filter queue >> $GITHUB_STEP_SUMMARY || true

      - name: Check for regressions
        run: |
          critcmp base pr --threshold 10 || echo "::warning::Some benchmarks show >10% regression"

  benchmark-report:
    name: Generate Benchmark Report
    runs-on: ubuntu-latest
    needs: benchmark
    if: github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v4

      - name: Download benchmark results
        uses: actions/download-artifact@v4
        with:
          name: benchmark-results
          path: target/criterion/

      - name: Generate summary report
        run: |
          echo "# Benchmark Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Benchmark run completed on $(date)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Available Reports" >> $GITHUB_STEP_SUMMARY
          echo "- Serialization benchmarks" >> $GITHUB_STEP_SUMMARY
          echo "- Map operation benchmarks" >> $GITHUB_STEP_SUMMARY
          echo "- Queue operation benchmarks" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Full HTML reports are available in the benchmark-results artifact." >> $GITHUB_STEP_SUMMARY
